{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80724fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b0cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importing the module \n",
    "from pytube import YouTube \n",
    "  \n",
    "# where to save \n",
    " #to_do \n",
    "  \n",
    "# link of the video to be downloaded \n",
    "link=\"https://www.youtube.com/watch?v=MT9RYxLTyb0&ab_channel=CapitalTV\"\n",
    "  \n",
    "try: \n",
    "    # object creation using YouTube\n",
    "    # which was imported in the beginning \n",
    "    yt = YouTube(link) \n",
    "except: \n",
    "    print(\"Connection Error\") #to handle exception \n",
    "  \n",
    "# filters out all the files with \"mp4\" extension \n",
    "# mp4files = yt.filter('mp4') \n",
    "  \n",
    "#to set the name of the file\n",
    "yt.set_filename('GeeksforGeeks Video')  \n",
    "  \n",
    "# get the video with the extension and\n",
    "# resolution passed in the get() function \n",
    "d_video = yt.get() \n",
    "try: \n",
    "    # downloading the video \n",
    "    d_video.download('/video') \n",
    "except: \n",
    "    print(\"Some Error!\") \n",
    "print('Task Completed!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc6ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "yt = YouTube(\"https://www.youtube.com/watch?v=MT9RYxLTyb0&ab_channel=CapitalTV\")\n",
    "print(yt.title)\n",
    "stream = yt.streams[1]\n",
    "stream.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7602801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('Imran Khan Gets Emotional While Meeting His Sons Qasim And Suleman | Capital TV.mp4') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fef5580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e28e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from mediapipe.python.solutions.drawing_utils import _normalized_to_pixel_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc6b4113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize_face_simple(image, factor=3.0):\n",
    "\t# automatically determine the size of the blurring kernel based\n",
    "\t# on the spatial dimensions of the input image\n",
    "\t(h, w) = image.shape[:2]\n",
    "\tkW = int(w / factor)\n",
    "\tkH = int(h / factor)\n",
    "\t# ensure the width of the kernel is odd\n",
    "\tif kW % 2 == 0:\n",
    "\t\tkW -= 1\n",
    "\t# ensure the height of the kernel is odd\n",
    "\tif kH % 2 == 0:\n",
    "\t\tkH -= 1\n",
    "\t# apply a Gaussian blur to the input image using our computed\n",
    "\t# kernel size\n",
    "\treturn cv2.GaussianBlur(image, (kW, kH), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2bfef78",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m     model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('model.pkl' , 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "252c97ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('model_pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf45736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from mediapipe.python.solutions.drawing_utils import _normalized_to_pixel_coordinates\n",
    "def face_detection(image_path):\n",
    "    \n",
    "        mp_face = mp.solutions.face_detection.FaceDetection(model_selection=1, # model selection\n",
    "        min_detection_confidence=0.5 # confidence threshold\n",
    "        )\n",
    "        cap = cv2.VideoCapture(image_path)\n",
    "        print(cap)\n",
    "        while(cap.isOpened()):\n",
    "            ret, test = cap.read()  \n",
    "            print(test.shape)\n",
    "            if ret==True:\n",
    "                image_rows, image_cols, _ = test.shape\n",
    "                image_input = cv2.cvtColor(test, cv2.COLOR_BGR2RGB)\n",
    "                results = mp_face.process(image_input)\n",
    "                detection=results.detections\n",
    "                if detection!=None:\n",
    "                    for i in range(len(detection)):\n",
    "\n",
    "                        relative_bounding_box=detection[i].location_data.relative_bounding_box\n",
    "                    #     relative_bounding_box = location.relative_bounding_box\n",
    "                        rect_start_point = _normalized_to_pixel_coordinates(\n",
    "                        relative_bounding_box.xmin, relative_bounding_box.ymin, image_cols,\n",
    "                        image_rows)\n",
    "                        rect_end_point = _normalized_to_pixel_coordinates(\n",
    "                        relative_bounding_box.xmin + relative_bounding_box.width,\n",
    "                        relative_bounding_box.ymin + relative_bounding_box.height, image_cols,\n",
    "                        image_rows)\n",
    "                        color = (255, 0, 0)\n",
    "                        thickness = 2\n",
    "                        test=cv2.rectangle(image_input, rect_start_point, rect_end_point, color,thickness)\n",
    "\n",
    "    #                 xleft,ytop=rect_start_point\n",
    "    #                 xright,ybot=rect_end_point\n",
    "    #                 print(rect_start_point,rect_end_point)\n",
    "    #                 crop_img = image_input[ytop: ybot, xleft: xright]\n",
    "    #                 crop_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)\n",
    "    #                 crop_img_resize=cv2.resize(crop_img,(64,64))\n",
    "    #             image_rows, image_cols, _ = test.shape\n",
    "    #             print(image_rows,image_cols)\n",
    "    #             image_input = cv2.cvtColor(test, cv2.COLOR_BGR2RGB)\n",
    "    #             results = mp_face.process(image_input)\n",
    "    #             detection=results.detections\n",
    "\n",
    "    #             if detection!=None:\n",
    "    #                 print(len(detection))\n",
    "    #                 for i in range(len(detection)):\n",
    "\n",
    "    #                     relative_bounding_box=detection[i].location_data.relative_bounding_box\n",
    "    #                 #     relative_bounding_box = location.relative_bounding_box\n",
    "    #                     rect_start_point = _normalized_to_pixel_coordinates(\n",
    "    #                     relative_bounding_box.xmin, relative_bounding_box.ymin, image_cols,\n",
    "    #                     image_rows)\n",
    "    #                     rect_end_point = _normalized_to_pixel_coordinates(\n",
    "    #                     relative_bounding_box.xmin + relative_bounding_box.width,\n",
    "    #                     relative_bounding_box.ymin + relative_bounding_box.height, image_cols,\n",
    "    #                     image_rows)\n",
    "    #                     try: \n",
    "    #                         xleft,ytop=rect_start_point\n",
    "    #                         xright,ybot=rect_end_point\n",
    "    #                         print(rect_start_point,rect_end_point)\n",
    "    #                         print(rect_start_point,rect_end_point)\n",
    "    #                         crop_img = image_input[ytop: ybot, xleft: xright]\n",
    "    #                         crop_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)\n",
    "    #                         crop_img_resize=cv2.resize(crop_img,(64,64))\n",
    "    #                     except TypeError:\n",
    "    #                         pass\n",
    "\n",
    "    #                     if model.predict(crop_img_resize.reshape(1,-1))==1:\n",
    "\n",
    "\n",
    "    #                         image_input[ytop: ybot, xleft: xright]=anonymize_face_simple(crop_img)\n",
    "                plt.imshow(test)\n",
    "                cv2.imshow('Video', test) \n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    break\n",
    " \n",
    "# Break the loop\n",
    "            else:\n",
    "                break\n",
    "\n",
    "# When everything done, release\n",
    "# the video capture object\n",
    "        cap.release()\n",
    " \n",
    "# Closes all the frames\n",
    "        cv2.destroyAllWindows() \n",
    "   \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6205c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detection('imran_video.mp4') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb38bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To capture video from existing video.   \n",
    "cap = cv2.VideoCapture('imran_video.mp4')  \n",
    "  \n",
    "while True:  \n",
    "    # Read the frame  \n",
    "    _, img = cap.read()  \n",
    "  \n",
    "    # Convert to grayscale  \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
    "  \n",
    "    \n",
    "  \n",
    "    # Display  \n",
    "    cv2.imshow('Video', img)  \n",
    "  \n",
    "    # Stop if escape key is pressed  \n",
    "    k = cv2.waitKey(30) & 0xff  \n",
    "    if k==27:  \n",
    "        break  \n",
    "          \n",
    "# Release the VideoCapture object  \n",
    "cap.release()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from mediapipe.python.solutions.drawing_utils import _normalized_to_pixel_coordinates\n",
    "def face_detections(image_path):\n",
    "    \n",
    "        mp_face = mp.solutions.face_detection.FaceDetection(model_selection=1, # model selection\n",
    "        min_detection_confidence=0.5 # confidence threshold\n",
    "        )\n",
    "        cap = cv2.VideoCapture(image_path)\n",
    "#         print(cap)\n",
    "        while(cap.isOpened()):\n",
    "            ret, test = cap.read()  \n",
    "           \n",
    "            if ret==True:\n",
    "                image_rows, image_cols, _ = test.shape\n",
    "                image_input = cv2.cvtColor(test, cv2.COLOR_BGR2RGB)\n",
    "                results = mp_face.process(image_input)\n",
    "                detection=results.detections\n",
    "                if detection!=None:\n",
    "                    for i in range(len(detection)):\n",
    "\n",
    "                        relative_bounding_box=detection[i].location_data.relative_bounding_box\n",
    "                    #     relative_bounding_box = location.relative_bounding_box\n",
    "                        rect_start_point = _normalized_to_pixel_coordinates(\n",
    "                        relative_bounding_box.xmin, relative_bounding_box.ymin, image_cols,\n",
    "                        image_rows)\n",
    "                        rect_end_point = _normalized_to_pixel_coordinates(\n",
    "                        relative_bounding_box.xmin + relative_bounding_box.width,\n",
    "                        relative_bounding_box.ymin + relative_bounding_box.height, image_cols,\n",
    "                        image_rows)\n",
    "                        color = (255, 0, 0)\n",
    "                        thickness = 2\n",
    "                        test=cv2.rectangle(test, rect_start_point, rect_end_point, color,thickness)\n",
    "                        try:\n",
    "                            xleft,ytop=rect_start_point\n",
    "                            xright,ybot=rect_end_point\n",
    "#                             print(rect_start_point,rect_end_point)\n",
    "                            crop_img = image_input[ytop: ybot, xleft: xright]\n",
    "                            crop_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)\n",
    "                            crop_img_resize=cv2.resize(crop_img,(64,64))\n",
    "#                             plt.imshow(crop_img)\n",
    "                        except:\n",
    "                            pass\n",
    "                        print(model.predict_proba(crop_img_resize.reshape(1,-1))[0][1])\n",
    "                        if model.predict(crop_img_resize.reshape(1,-1))==1 and model.predict_proba(crop_img_resize.reshape(1,-1))[0][1]>0.6:\n",
    "                            test[ytop: ybot, xleft: xright]=anonymize_face_simple(crop_img)\n",
    "                       \n",
    "#                         if model.predict(crop_img_resize.reshape(1,-1))==1:\n",
    "#                             image_input[ytop: ybot, xleft: xright]=anonymize_face_simple(crop_img)\n",
    "    #             image_rows, image_cols, _ = test.shape\n",
    "    #             print(image_rows,image_cols)\n",
    "    #             image_input = cv2.cvtColor(test, cv2.COLOR_BGR2RGB)\n",
    "    #             results = mp_face.process(image_input)\n",
    "    #             detection=results.detections\n",
    "\n",
    "    #             if detection!=None:\n",
    "    #                 print(len(detection))\n",
    "    #                 for i in range(len(detection)):\n",
    "\n",
    "    #                     relative_bounding_box=detection[i].location_data.relative_bounding_box\n",
    "    #                 #     relative_bounding_box = location.relative_bounding_box\n",
    "    #                     rect_start_point = _normalized_to_pixel_coordinates(\n",
    "    #                     relative_bounding_box.xmin, relative_bounding_box.ymin, image_cols,\n",
    "    #                     image_rows)\n",
    "    #                     rect_end_point = _normalized_to_pixel_coordinates(\n",
    "    #                     relative_bounding_box.xmin + relative_bounding_box.width,\n",
    "    #                     relative_bounding_box.ymin + relative_bounding_box.height, image_cols,\n",
    "    #                     image_rows)\n",
    "    #                     try: \n",
    "    #                         xleft,ytop=rect_start_point\n",
    "    #                         xright,ybot=rect_end_point\n",
    "    #                         print(rect_start_point,rect_end_point)\n",
    "    #                         print(rect_start_point,rect_end_point)\n",
    "    #                         crop_img = image_input[ytop: ybot, xleft: xright]\n",
    "    #                         crop_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)\n",
    "    #                         crop_img_resize=cv2.resize(crop_img,(64,64))\n",
    "    #                     except TypeError:\n",
    "    #                         pass\n",
    "\n",
    "    #                     if model.predict(crop_img_resize.reshape(1,-1))==1:\n",
    "\n",
    "\n",
    "    #                         image_input[ytop: ybot, xleft: xright]=anonymize_face_simple(crop_img)\n",
    "                \n",
    "                cv2.imshow('Video', test) \n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    break\n",
    " \n",
    "    # Break the loop\n",
    "            else:\n",
    "                break\n",
    "\n",
    "# When everything done, release\n",
    "# the video capture object\n",
    "        cap.release()\n",
    " \n",
    "    # Closes all the frames\n",
    "        cv2.destroyAllWindows() \n",
    "   \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab4bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detections('imran_video.mp4') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18bb15b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
